{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous-Time Markov Chains: The Yule-Furry Process\n",
    "\n",
    "In this notebook, we will simulate a continuous-time Markov chain (CTMC) and \n",
    "compare the results to known analytical formulas. The example we will use is \n",
    "the **Yule-Furry process**, also known as the linear birth process.\n",
    "\n",
    "Recall from the board that in this process, each individual independently gives \n",
    "birth at rate $\\beta$. When the population size is $n$, the total birth rate is \n",
    "$n\\beta$. Since there are no deaths, the population can only grow.\n",
    "\n",
    "## Why are inter-event times exponentially distributed?\n",
    "\n",
    "The defining property of a CTMC is that it is *memoryless*: the future depends \n",
    "only on the current state, not on how long the system has been in that state. \n",
    "The exponential distribution is the unique continuous distribution with this \n",
    "memoryless property — if $T \\sim \\text{Exp}(\\lambda)$, then \n",
    "$P(T > t + s \\mid T > t) = P(T > s)$ for all $t, s \\geq 0$.\n",
    "\n",
    "For a single individual with birth rate $\\beta$, the time until its next birth \n",
    "is $\\text{Exp}(\\beta)$. When there are $n$ independent individuals each with \n",
    "rate $\\beta$, the time until the *first* birth among all of them is the minimum \n",
    "of $n$ independent exponentials. A standard result from probability is that the \n",
    "minimum of $n$ independent $\\text{Exp}(\\beta)$ random variables is \n",
    "$\\text{Exp}(n\\beta)$. So when the population is $n$, the time until the next \n",
    "event is exponentially distributed with rate $n\\beta$ (equivalently, mean \n",
    "$1/(n\\beta)$).\n",
    "\n",
    "## The Gillespie algorithm\n",
    "\n",
    "The **Gillespie algorithm** (also called the stochastic simulation algorithm) is \n",
    "a general method for exactly simulating CTMCs. The idea is simple: rather than \n",
    "advancing time in fixed steps and checking whether events occur (which would \n",
    "require very small time steps for accuracy), we jump directly from one event to \n",
    "the next. At each step:\n",
    "1. Compute the total rate of all possible events given the current state.\n",
    "2. Draw the time until the next event from the corresponding exponential \n",
    "distribution.\n",
    "3. Determine which event occurs (in our case there is only one type — a birth).\n",
    "4. Update the state and repeat.\n",
    "\n",
    "This is exact (no discretization error) and efficient, since we skip over all \n",
    "the dead time between events. For the Yule-Furry process, the algorithm is \n",
    "particularly simple because there is only one type of event (birth), so step 3 \n",
    "is trivial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import comb # computes binomial coefficients, C(n, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating a single realization\n",
    "\n",
    "The simulation algorithm is as follows:\n",
    "1. Start with $n_0$ individuals at time $t=0$.\n",
    "2. Draw an inter-event time $\\Delta t$ from $\\text{Exp}(n\\beta)$. In numpy, \n",
    "`rng.exponential(scale)` takes the *scale* parameter, which is $1/\\text{rate} = 1/(n\\beta)$.\n",
    "3. Advance time: $t \\leftarrow t + \\Delta t$.\n",
    "4. If $t > T_{\\max}$, stop.\n",
    "5. Otherwise, increment the population: $n \\leftarrow n + 1$.\n",
    "6. Record the new time and population size, and go back to step 2.\n",
    "\n",
    "In the cell below, implement this algorithm using a while loop. Store the \n",
    "times and population sizes in lists so that you can plot them afterward. Use \n",
    "`plt.step()` to plot the result as a step function (which is the correct \n",
    "visualization for a jump process)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "rng = np.random.default_rng()\n\n# Parameters\nbeta = 0.1\nn0 = 5\nT_max = 10\n\n# Initialize lists to store the trajectory\ntimes = [0.0]\npop = [n0]\n\n# Run the simulation\nt = 0.0\nn = n0\nwhile True:\n    # Draw inter-event time\n    dt = rng.exponential(1.0 / (n * beta))\n    t += dt\n    if t > T_max:\n        break\n    n += 1\n    times.append(t)\n    pop.append(n)\n\n# Append the final time so the plot extends to T_max\ntimes.append(T_max)\npop.append(n)\n\n# TODO: Plot the trajectory using plt.step(times, pop, where='post')\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running many simulations\n",
    "\n",
    "A single realization tells us little about the statistics of the process. To \n",
    "understand the distribution of outcomes, we need to run many simulations and \n",
    "collect the results.\n",
    "\n",
    "First, wrap your simulation code from above into a function that takes \n",
    "parameters and returns the trajectory (times and population sizes). Then, run \n",
    "it `N_sim` times and:\n",
    "1. Plot all trajectories on the same axes.\n",
    "2. Overlay the analytical expected value $E[N(t)] = n_0 e^{\\beta t}$ as a \n",
    "dashed line for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_yule_furry(beta, n0, T_max, rng):\n",
    "    \"\"\"Simulate one realization of the Yule-Furry process.\n",
    "    \n",
    "    Returns lists of times and population sizes.\"\"\"\n",
    "    times = [0.0]\n",
    "    pop = [n0]\n",
    "    # TODO: Fill in the simulation loop (same as above)\n",
    "\n",
    "    return times, pop\n",
    "\n",
    "# Parameters\n",
    "beta = 0.1\n",
    "n0 = 5\n",
    "T_max = 10\n",
    "N_sim = 200\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "# TODO: Run N_sim simulations. For each one:\n",
    "#   - Call simulate_yule_furry and store the final population size.\n",
    "#   - Plot the trajectory with plt.step(..., where='post', alpha=0.15, color='blue', linewidth=0.5)\n",
    "#     so the trajectories are semi-transparent.\n",
    "final_pops = np.zeros(N_sim, dtype=int)\n",
    "\n",
    "\n",
    "# Overlay the analytical expected value\n",
    "# t_analytical = np.linspace(0, T_max, 200)\n",
    "# E_N = n0 * np.exp(beta * t_analytical)\n",
    "# plt.plot(t_analytical, E_N, 'r--', linewidth=2, label='$E[N(t)] = n_0 e^{\\\\beta t}$')\n",
    "\n",
    "# TODO: Print the sample mean and analytical mean n0*exp(beta*T_max) to compare.\n",
    "#   You can also compare the sample variance to the analytical variance:\n",
    "#   Var[N(t)] = n0 * (1 - exp(-beta*t)) * exp(2*beta*t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing to the analytical distribution\n",
    "\n",
    "The Yule-Furry process has a known probability distribution. For $n \\geq n_0$,\n",
    "$$\n",
    "p_n(t) = \\binom{n-1}{n_0-1} e^{-\\beta n_0 t} \\left(1 - e^{-\\beta t}\\right)^{n - n_0}.\n",
    "$$\n",
    "This is a *negative binomial distribution* in which the probability of \n",
    "\"success\" in a single trial, $e^{-\\beta t}$, decreases exponentially with time.\n",
    "\n",
    "In the cell below, create a histogram of the final population sizes from your \n",
    "simulations and overlay the analytical PMF. Use `density=True` in `plt.hist()` \n",
    "so that the histogram is normalized to a probability distribution. To compute \n",
    "the binomial coefficient, use `scipy.special.comb` which we imported above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the analytical PMF over a range of population sizes\n",
    "n_vals = np.arange(n0, np.max(final_pops) + 5)\n",
    "p_analytical = comb(n_vals - 1, n0 - 1) * \\\n",
    "    np.exp(-beta * n0 * T_max) * (1 - np.exp(-beta * T_max))**(n_vals - n0)\n",
    "\n",
    "# TODO: Plot a histogram of final_pops and overlay p_analytical.\n",
    "#   - Use integer-width bins: np.arange(n0 - 0.5, np.max(final_pops) + 1.5, 1)\n",
    "#   - Use density=True so the histogram is normalized.\n",
    "#   - Plot the analytical PMF with plt.plot(n_vals, p_analytical, 'ro-', markersize=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further exploration\n",
    "\n",
    "Try experimenting with different parameter values:\n",
    "- What happens when you increase $\\beta$? The population grows faster, leading \n",
    "to larger final sizes and wider distributions. Be careful with large $\\beta$ or \n",
    "large $T_{\\max}$ as the population can grow very large and the simulation will \n",
    "slow down.\n",
    "- What happens when $n_0 = 1$? The distribution becomes a geometric \n",
    "distribution. Try it!\n",
    "- How many simulations do you need for the histogram to closely match the \n",
    "analytical PMF?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}